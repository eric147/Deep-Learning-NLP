Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.26666666666666666
Precision Average: 0.4057971014492754
Recall Average: 0.19858156028368795
Error: 0.9242871189773845
ROC: 0.5884614087736454
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.23410404624277456
Precision Average: 0.147005444646098
Recall Average: 0.574468085106383
Error: 0.7394296951819076
ROC: 0.663092468332378
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.20503597122302158
Precision: 0.13734939759036144
Recall: 0.40425531914893614
Accuracy: 0.7826941986234022
ROC: 0.6075687583594653
SVM:
F1 Score Average: 0.20472440944881892
Precision Average: 0.12560386473429952
Recall Average: 0.5531914893617021
Error: 0.7020648967551623
ROC: 0.6331726068044643
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.15781710914454278
precision: 0.07467532467532467
roc: 0.5376976767710827
f1: 0.13876319758672698
recall: 0.9787234042553191

Perceptron with the transformed features and concatenated bag of words accuracy: 0.4144542772861357
precision: 0.0904836193447738
roc: 0.6033707612592867
f1: 0.163035839775123
recall: 0.8226950354609929
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.20512820512820515
Precision Average: 0.43478260869565216
Recall Average: 0.1342281879194631
Error: 0.923795476892822
ROC: 0.5602175422355936
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.2799325463743676
Precision Average: 0.18693693693693694
Recall Average: 0.5570469798657718
Error: 0.7900688298918387
ROC: 0.6827675217631246
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.24664879356568367
Precision: 0.1541038525963149
Recall: 0.6174496644295302
Accuracy: 0.7236971484759095
ROC: 0.6747725775728552
SVM:
F1 Score Average: 0.24884792626728108
Precision Average: 0.16135458167330677
Recall Average: 0.5436241610738255
Error: 0.7595870206489675
ROC: 0.6601409930037563
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.44198623402163223
precision: 0.10241935483870968
roc: 0.6309490324533138
f1: 0.18286537077033838
recall: 0.8523489932885906

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7374631268436578
precision: 0.12328767123287672
roc: 0.59257650472647
f1: 0.19090909090909092
recall: 0.4228187919463087
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.26168224299065423
Precision Average: 0.4057971014492754
Recall Average: 0.19310344827586207
Error: 0.9223205506391348
ROC: 0.5856994213322136
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.28571428571428575
Precision Average: 0.1927710843373494
Recall Average: 0.5517241379310345
Error: 0.8033431661750245
ROC: 0.6871908143334368
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.0970873786407767
Precision: 0.16393442622950818
Recall: 0.06896551724137931
Accuracy: 0.9085545722713865
ROC: 0.5209835526916266
SVM:
F1 Score Average: 0.23170731707317072
Precision Average: 0.1487279843444227
Recall Average: 0.5241379310344828
Error: 0.7522123893805309
ROC: 0.6469286796517042
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8923303834808259
precision: 0.16964285714285715
roc: 0.5409010423321955
f1: 0.14785992217898836
recall: 0.1310344827586207

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8593903638151426
precision: 0.14925373134328357
roc: 0.5581862324528577
f1: 0.17341040462427745
recall: 0.20689655172413793
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.026143790849673203
Precision Average: 0.6666666666666666
Recall Average: 0.013333333333333334
Error: 0.9267813267813267
ROC: 0.5064014146772767
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.2804005722460658
Precision Average: 0.1785063752276867
Recall Average: 0.6533333333333333
Error: 0.7528255528255529
ROC: 0.7070380194518125
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.22379603399433426
Precision: 0.1420863309352518
Recall: 0.5266666666666666
Accuracy: 0.7307125307125307
ROC: 0.6368081343943413
SVM:
F1 Score Average: 0.26888217522658614
Precision Average: 0.173828125
Recall Average: 0.5933333333333334
Error: 0.7621621621621621
ROC: 0.6844650751547304
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.28992628992628994
precision: 0.08626198083067092
roc: 0.5706896551724139
f1: 0.1574344023323615
recall: 0.9

Perceptron with the transformed features and concatenated bag of words accuracy: 0.341031941031941
precision: 0.0884588804422944
roc: 0.5767992926613617
f1: 0.16030056355666875
recall: 0.8533333333333334
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.24390243902439027
Precision Average: 0.43103448275862066
Recall Average: 0.17006802721088435
Error: 0.9238329238329238
ROC: 0.5762946068257812
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.23941605839416055
Precision Average: 0.1524163568773234
Recall Average: 0.5578231292517006
Error: 0.743980343980344
ROC: 0.6581488527614435
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.0
Precision: 0.0
Recall: 0.0
Accuracy: 0.9272727272727272
ROC: 0.4997351694915254
SVM:
F1 Score Average: 0.21986754966887412
Precision Average: 0.13651315789473684
Recall Average: 0.564625850340136
Error: 0.7105651105651105
ROC: 0.6432769082209153
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.10171990171990172
precision: 0.07313357034027425
roc: 0.5064802404012452
f1: 0.13610586011342155
recall: 0.9795918367346939

Perceptron with the transformed features and concatenated bag of words accuracy: 0.11793611793611794
precision: 0.0743801652892562
roc: 0.5152196471809063
f1: 0.13826212193951032
recall: 0.9795918367346939
AUC: 0.5634148787689022
F1: 0.2007046689319179
Accuracy: 0.9242034794247184
Recall: 0.14186291140464616
Precision: 0.468815592203898

SVM without domain adaptationAUC: 0.679647535328439
F1: 0.2639135017943309
Accuracy: 0.7659295176109335
Recall: 0.5788791330976446
Precision: 0.17152723960507887

Perceptron without transfer learningrecall: 0.5147567919100654
accuracy: 0.6468290172714951
precision: 0.13029561609641713
roc: 0.5857839625221206
f1: 0.15646490010371142

Perceptron with transfer learningrecall: 0.7683397434074448
accuracy: 0.37675598365863855
precision: 0.10122661756556735
roc: 0.5573435294260503
f1: 0.15260575059636733

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.6570671098398935
accuracy: 0.49405516538259897
precision: 0.10517281353049694
roc: 0.5692304876561766
f1: 0.1651836041609341
SVM with BoW and transformed featuresAUC: 0.6535968525671141
F1: 0.2348058755369462
Accuracy: 0.7373183159023867
Recall: 0.555782553028696
Precision: 0.14920554272935316
MLP scoresAUC: 0.5879736385019628
F1: 0.1545136354847632
Accuracy: 0.8145862354711912
Recall: 0.32346743349730245
Precision: 0.11949480147028727
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6713286713286714
Precision Average: 0.6486486486486487
Recall Average: 0.6956521739130435
Error: 0.8097165991902834
ROC: 0.7747923790913531
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7657142857142857
Precision Average: 0.6320754716981132
Recall Average: 0.9710144927536232
Error: 0.8340080971659919
ROC: 0.8759566845790587
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.48591549295774644
Precision: 0.3209302325581395
Recall: 1.0
Accuracy: 0.4089068825910931
ROC: 0.5898876404494382
SVM:
F1 Score Average: 0.6567164179104478
Precision Average: 0.5
Recall Average: 0.9565217391304348
Error: 0.7206477732793523
ROC: 0.7928676111382511
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.7408906882591093
precision: 0.6470588235294118
roc: 0.5628562123432665
f1: 0.2558139534883721
recall: 0.15942028985507245

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7651821862348178
precision: 0.5567010309278351
roc: 0.7705178309721543
f1: 0.6506024096385542
recall: 0.782608695652174
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5123966942148761
Precision Average: 0.6595744680851063
Recall Average: 0.4189189189189189
Error: 0.7611336032388664
ROC: 0.6632166848929855
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.49214659685863876
Precision Average: 0.4017094017094017
Recall Average: 0.6351351351351351
Error: 0.6072874493927125
ROC: 0.6152554288392438
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6666666666666666
Precision: 0.8076923076923077
Recall: 0.5675675675675675
Accuracy: 0.8299595141700404
ROC: 0.7548820496797376
SVM:
F1 Score Average: 0.7830687830687831
Precision Average: 0.6434782608695652
Recall Average: 1.0
Error: 0.8340080971659919
ROC: 0.8815028901734104
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.32793522267206476
precision: 0.30833333333333335
roc: 0.5202312138728324
f1: 0.47133757961783446
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.6963562753036437
precision: 0.49612403100775193
roc: 0.7445711607561318
f1: 0.6305418719211823
recall: 0.8648648648648649
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.56
Precision Average: 0.6862745098039216
Recall Average: 0.47297297297297297
Error: 0.7773279352226721
ROC: 0.6902437119200125
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7675675675675677
Precision Average: 0.6396396396396397
Recall Average: 0.9594594594594594
Error: 0.8259109311740891
ROC: 0.8641227933135448
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6140350877192983
Precision: 0.875
Recall: 0.47297297297297297
Accuracy: 0.8218623481781376
ROC: 0.7220356194344634
SVM:
F1 Score Average: 0.7708333333333333
Precision Average: 0.6271186440677966
Recall Average: 1.0
Error: 0.8218623481781376
ROC: 0.8728323699421965
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.5870445344129555
precision: 0.42045454545454547
roc: 0.7052023121387283
f1: 0.5920000000000001
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7165991902834008
precision: 0.5166666666666667
roc: 0.7512888611154508
f1: 0.6391752577319588
recall: 0.8378378378378378
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6461538461538461
Precision Average: 0.823529411764706
Recall Average: 0.5316455696202531
Error: 0.8137651821862348
ROC: 0.7390370705244123
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.48587570621468934
Precision Average: 0.4387755102040816
Recall Average: 0.5443037974683544
Error: 0.631578947368421
ROC: 0.6084614225437011
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.7572815533980581
Precision: 0.6141732283464567
Recall: 0.9873417721518988
Accuracy: 0.7975708502024291
ROC: 0.847837552742616
SVM:
F1 Score Average: 0.8020304568527918
Precision Average: 0.6694915254237288
Recall Average: 1.0
Error: 0.8421052631578947
ROC: 0.8839285714285714
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.5263157894736842
precision: 0.4030612244897959
roc: 0.6517857142857143
f1: 0.5745454545454546
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8097165991902834
precision: 0.6951219512195121
roc: 0.7863547317661241
f1: 0.7080745341614906
recall: 0.7215189873417721
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5954198473282443
Precision Average: 0.6190476190476191
Recall Average: 0.5735294117647058
Error: 0.7862903225806451
ROC: 0.7200980392156863
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.37583892617449666
Precision Average: 0.345679012345679
Recall Average: 0.4117647058823529
Error: 0.625
ROC: 0.5586601307189542
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.7234042553191489
Precision: 0.5666666666666667
Recall: 1.0
Accuracy: 0.7903225806451613
ROC: 0.8555555555555556
SVM:
F1 Score Average: 0.768361581920904
Precision Average: 0.6238532110091743
Recall Average: 1.0
Error: 0.8346774193548387
ROC: 0.8861111111111112
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.7983870967741935
precision: 0.6125
roc: 0.7741830065359477
f1: 0.6621621621621623
recall: 0.7205882352941176

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7137096774193549
precision: 0.3333333333333333
roc: 0.5053921568627451
f1: 0.07792207792207792
recall: 0.04411764705882353
AUC: 0.7174775771288899
F1: 0.5970598118051276
Accuracy: 0.7896467284837403
Recall: 0.5385438094379789
Precision: 0.6874149314700003

SVM without domain adaptationAUC: 0.7044912919989005
F1: 0.5774286165059357
Accuracy: 0.7047570850202429
Recall: 0.704335518139785
Precision: 0.49157580711938315

Perceptron without transfer learningrecall: 0.632768509388018
accuracy: 0.6447433720778373
precision: 0.5301095545281591
roc: 0.6412150787774472
f1: 0.47230448740640174

Perceptron with transfer learningrecall: 0.776001705029838
accuracy: 0.5961146663184014
precision: 0.47828158536141735
roc: 0.6428516918352979
f1: 0.5111718299627647

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.6501896065510944
accuracy: 0.7403127856863002
precision: 0.5195894026310198
roc: 0.7116249482945212
f1: 0.5412632302750527
SVM with BoW and transformed featuresAUC: 0.863448510758708
F1: 0.756202114617252
Accuracy: 0.8106601802272431
Recall: 0.9913043478260869
Precision: 0.612788328274053
MLP scoresAUC: 0.7540396835723622
F1: 0.6494606112121837
Accuracy: 0.7297244351573724
Recall: 0.8055764625384878
Precision: 0.636892487052714
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7972972972972973
Precision Average: 0.7788778877887789
Recall Average: 0.8166089965397924
Error: 0.8659217877094972
ROC: 0.853023970217091
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.819767441860465
Precision Average: 0.706766917293233
Recall Average: 0.9757785467128027
Error: 0.8614525139664805
ROC: 0.8913546198910549
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.47668393782383406
Precision: 0.9484536082474226
Recall: 0.31833910034602075
Accuracy: 0.7743016759776536
ROC: 0.6550441376317562
SVM:
F1 Score Average: 0.8425655976676386
Precision Average: 0.7279596977329975
Recall Average: 1.0
Error: 0.8793296089385475
ROC: 0.9108910891089109
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8011173184357542
precision: 0.6377171215880894
roc: 0.8241746319960717
f1: 0.7427745664739884
recall: 0.889273356401384

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8122905027932961
precision: 0.6531645569620254
roc: 0.8333304783765574
f1: 0.7543859649122807
recall: 0.8927335640138409
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.796551724137931
Precision Average: 0.8048780487804879
Recall Average: 0.78839590443686
Error: 0.8681564245810056
ROC: 0.8476863243114533
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.8083333333333332
Precision Average: 0.6814988290398126
Recall Average: 0.9931740614334471
Error: 0.8458100558659218
ROC: 0.8836302200854942
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.3286908077994429
Precision: 0.893939393939394
Recall: 0.20136518771331058
Accuracy: 0.7307262569832402
ROC: 0.5948686403682832
SVM:
F1 Score Average: 0.8208092485549133
Precision Average: 0.7117794486215538
Recall Average: 0.9692832764505119
Error: 0.8614525139664805
ROC: 0.8891266880591431
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.32737430167597764
precision: 0.32737430167597764
roc: 0.5
f1: 0.49326599326599324
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8167597765363128
precision: 0.6632911392405063
roc: 0.8366338598301453
f1: 0.7616279069767441
recall: 0.89419795221843
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.806282722513089
Precision Average: 0.7993079584775087
Recall Average: 0.8133802816901409
Error: 0.8759776536312849
ROC: 0.8592269657223209
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.8315946348733235
Precision Average: 0.7209302325581395
Recall Average: 0.9823943661971831
Error: 0.8737430167597765
ROC: 0.9028174776976094
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.5806451612903226
Precision: 0.84
Recall: 0.44366197183098594
Accuracy: 0.7966480446927374
ROC: 0.7021910513819414
SVM:
F1 Score Average: 0.8209606986899565
Precision Average: 0.6997518610421837
Recall Average: 0.9929577464788732
Error: 0.8625698324022346
ROC: 0.8974608699661142
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.6223463687150838
precision: 0.4552980132450331
roc: 0.7149241603466956
f1: 0.6193693693693694
recall: 0.9683098591549296

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8
precision: 0.6816608996539792
roc: 0.7715445702035454
f1: 0.6876090750436299
recall: 0.6936619718309859
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7254237288135594
Precision Average: 0.7254237288135593
Recall Average: 0.7254237288135593
Error: 0.8189944134078212
ROC: 0.7952118644067797
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.8083916083916083
Precision Average: 0.6880952380952381
Recall Average: 0.9796610169491525
Error: 0.846927374301676
ROC: 0.8806638418079096
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.01346801346801347
Precision: 1.0
Recall: 0.006779661016949152
Accuracy: 0.6726256983240223
ROC: 0.5033898305084745
SVM:
F1 Score Average: 0.7907608695652174
Precision Average: 0.6598639455782312
Recall Average: 0.9864406779661017
Error: 0.8279329608938547
ROC: 0.8682203389830508
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.4201117318435754
precision: 0.36240786240786244
roc: 0.5675
f1: 0.5320108205590622
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7240223463687151
precision: 0.5476190476190477
roc: 0.7777966101694915
f1: 0.690863579474343
recall: 0.9355932203389831
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7879799666110184
Precision Average: 0.7662337662337663
Recall Average: 0.8109965635738832
Error: 0.8582589285714286
ROC: 0.8459941495555366
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.8153409090909092
Precision Average: 0.6949152542372882
Recall Average: 0.9862542955326461
Error: 0.8549107142857143
ROC: 0.8889949163613644
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.0
Precision: 0.0
Recall: 0.0
Accuracy: 0.6752232142857143
ROC: 0.5
SVM:
F1 Score Average: 0.7896174863387978
Precision Average: 0.655328798185941
Recall Average: 0.993127147766323
Error: 0.828125
ROC: 0.8709437391724177
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.3247767857142857
precision: 0.3247767857142857
roc: 0.5
f1: 0.4903117101937658
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.6127232142857143
precision: 0.4534883720930232
roc: 0.6971713385021726
f1: 0.6114221724524076
recall: 0.9381443298969072
AUC: 0.8402286548426362
F1: 0.782707087874579
Accuracy: 0.8574618415802074
Recall: 0.7909610950108472
Precision: 0.7749442780188203

SVM without domain adaptationAUC: 0.8894922151686867
F1: 0.8166855855099279
Accuracy: 0.8565687350359138
Recall: 0.9834524573650463
Precision: 0.6984412942447422

Perceptron without transfer learningrecall: 0.7539944315597696
accuracy: 0.7064158519553072
precision: 0.5911628830259026
roc: 0.7190129744166489
f1: 0.6323443890404733

Perceptron with transfer learningrecall: 0.9715166431112628
accuracy: 0.49914530127693535
precision: 0.42151481692624965
roc: 0.6213197584685535
f1: 0.5755464919724358

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.8708662076598295
accuracy: 0.7531591679968077
precision: 0.5998448031137164
roc: 0.7832953714163824
f1: 0.701181739771881
SVM with BoW and transformed featuresAUC: 0.8873285450579272
F1: 0.8129427801633048
Accuracy: 0.8518819832402235
Recall: 0.988361769732362
Precision: 0.6909367502321816
MLP scoresAUC: 0.591098731978091
F1: 0.2798975840763226
Accuracy: 0.7299049780526736
Recall: 0.19402918418145326
Precision: 0.7364786004373634
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.47745358090185674
Precision Average: 0.6666666666666666
Recall Average: 0.371900826446281
Error: 0.8810386473429952
ROC: 0.6700381077068744
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.5682656826568266
Precision Average: 0.404553415061296
Recall Average: 0.9545454545454546
Error: 0.7880434782608695
ROC: 0.8570464189276071
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.27681660899653976
Precision: 0.851063829787234
Recall: 0.1652892561983471
Accuracy: 0.873792270531401
ROC: 0.580169380574421
SVM:
F1 Score Average: 0.3666666666666666
Precision Average: 0.22964509394572025
Recall Average: 0.9090909090909091
Error: 0.5410628019323671
ROC: 0.6935836440786936
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.6497584541062802
precision: 0.2716216216216216
roc: 0.7246951967924066
f1: 0.4093686354378819
recall: 0.8305785123966942

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8454106280193237
precision: 0.4734848484848485
roc: 0.7091131191041182
f1: 0.49407114624505927
recall: 0.5165289256198347
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.47214854111405835
Precision Average: 0.6402877697841727
Recall Average: 0.3739495798319328
Error: 0.8799034399517199
ROC: 0.6693567490421115
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.5180180180180181
Precision Average: 0.35384615384615387
Recall Average: 0.9663865546218487
Error: 0.7417018708509354
ROC: 0.8352017339705439
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.51270207852194
Precision: 0.5692307692307692
Recall: 0.46638655462184875
Accuracy: 0.8726614363307181
ROC: 0.7035949686428483
SVM:
F1 Score Average: 0.5389082462253194
Precision Average: 0.3723916532905297
Recall Average: 0.9747899159663865
Error: 0.7604103802051901
ROC: 0.8496218783496485
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8545564272782137
precision: 0.36363636363636365
roc: 0.5059368356221982
f1: 0.0321285140562249
recall: 0.01680672268907563

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8557634278817139
precision: 0.47619047619047616
roc: 0.5171324343690965
f1: 0.07722007722007723
recall: 0.04201680672268908
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5110565110565111
Precision Average: 0.6540880503144654
Recall Average: 0.41935483870967744
Error: 0.8799034399517199
ROC: 0.690160031136244
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.47311827956989244
Precision Average: 0.3361629881154499
Recall Average: 0.7983870967741935
Error: 0.7338563669281835
ROC: 0.7604426612330868
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.3629684055841293
Precision: 0.22192273135669363
Recall: 0.9959677419354839
Accuracy: 0.4767652383826192
ROC: 0.6906737219258683
SVM:
F1 Score Average: 0.475266731328807
Precision Average: 0.3128991060025543
Recall Average: 0.9879032258064516
Error: 0.6735063367531684
ROC: 0.8030360699649717
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.15027157513578757
precision: 0.1497584541062802
roc: 0.5003548616039745
f1: 0.2605042016806723
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.15268557634278818
precision: 0.15012106537530268
roc: 0.5017743080198722
f1: 0.26105263157894737
recall: 1.0
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5
Precision Average: 0.6211180124223602
Recall Average: 0.41841004184100417
Error: 0.8792999396499698
ROC: 0.6876958530784709
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.45432098765432105
Precision Average: 0.3222416812609457
Recall Average: 0.7698744769874477
Error: 0.7332528666264333
ROC: 0.7484774359549369
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.2872596153846154
Precision: 0.16771929824561405
Recall: 1.0
Accuracy: 0.28424864212432105
ROC: 0.581805359661495
SVM:
F1 Score Average: 0.39093959731543626
Precision Average: 0.24449108079748164
Recall Average: 0.9748953974895398
Error: 0.5618587809293905
ROC: 0.7335689963470265
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.3657211828605914
precision: 0.18429237947122862
roc: 0.6259287345604334
f1: 0.31081967213114753
recall: 0.9916317991631799

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8388654194327098
precision: 0.4416666666666666
roc: 0.674507674785041
f1: 0.4425887265135699
recall: 0.4435146443514644
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5893719806763286
Precision Average: 0.6892655367231638
Recall Average: 0.5147679324894515
Error: 0.8974049487024743
ROC: 0.7380177690616271
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.4516129032258065
Precision Average: 0.3252788104089219
Recall Average: 0.7383966244725738
Error: 0.7435123717561859
ROC: 0.7413814108278363
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.65625
Precision: 0.5575221238938053
Recall: 0.7974683544303798
Accuracy: 0.8805069402534701
ROC: 0.8459172758067393
SVM:
F1 Score Average: 0.525564803804994
Precision Average: 0.3658940397350993
Recall Average: 0.9324894514767933
Error: 0.7592033796016898
ROC: 0.8313855708088191
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8949909474954737
precision: 0.6507177033492823
roc: 0.761215605871516
f1: 0.6098654708520179
recall: 0.5738396624472574

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8527459263729632
precision: 0.4779874213836478
roc: 0.63111220062994
f1: 0.38383838383838387
recall: 0.3206751054852321
AUC: 0.6910537020050656
F1: 0.5100061227497509
Accuracy: 0.8835100831197759
Recall: 0.4196766438636693
Precision: 0.6542852071821657

SVM without domain adaptationAUC: 0.7885099321828022
F1: 0.4930671742249729
Accuracy: 0.7480733908845215
Recall: 0.8455180414803036
Precision: 0.3484166097385535

Perceptron without transfer learningrecall: 0.6524138841722952
accuracy: 0.7403217647864863
precision: 0.38691074059817365
roc: 0.703380961728109
f1: 0.43543287332297087

Perceptron with transfer learningrecall: 0.6825713393392415
accuracy: 0.5830597173752692
precision: 0.3240053044369553
roc: 0.6236262468901057
f1: 0.32453729883158894

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.4645470964358441
accuracy: 0.7090941956098997
precision: 0.4038900956201884
roc: 0.6067279473816136
f1: 0.3317541930792075
SVM with BoW and transformed featuresAUC: 0.782239231909832
F1: 0.4594692090682447
Accuracy: 0.6592083358843611
Recall: 0.955833779966016
Precision: 0.30506419475427704
MLP scoresAUC: 0.6804321413222744
F1: 0.419199341697445
Accuracy: 0.6775949055245059
Recall: 0.685022381437212
Precision: 0.4734917505028232
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7434052757793764
Precision Average: 0.7948717948717948
Recall Average: 0.6981981981981982
Error: 0.8900308324768756
ROC: 0.8224679406437062
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6268115942028987
Precision Average: 0.5242424242424243
Recall Average: 0.7792792792792793
Error: 0.7882836587872559
ROC: 0.7851123427022229
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6590909090909092
Precision: 0.8923076923076924
Recall: 0.5225225225225225
Accuracy: 0.8766700924974307
ROC: 0.7519403558018738
SVM:
F1 Score Average: 0.8208955223880597
Precision Average: 0.7006369426751591
Recall Average: 0.990990990990991
Error: 0.9013360739979445
ROC: 0.9329122731253224
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.841726618705036
precision: 0.5909090909090909
roc: 0.8958835666558702
f1: 0.7416107382550335
recall: 0.9954954954954955

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7954779033915724
precision: 0.8709677419354839
roc: 0.5581476949652715
f1: 0.21343873517786563
recall: 0.12162162162162163
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6882793017456359
Precision Average: 0.7709497206703909
Recall Average: 0.6216216216216216
Error: 0.8715313463514902
ROC: 0.7835138733940331
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7588652482269505
Precision Average: 0.6257309941520468
Recall Average: 0.963963963963964
Error: 0.8602261048304214
ROC: 0.8967622749247249
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.37154811715481173
Precision: 0.22816032887975335
Recall: 1.0
Accuracy: 0.22816032887975335
ROC: 0.5
SVM:
F1 Score Average: 0.7602131438721137
Precision Average: 0.6275659824046921
Recall Average: 0.963963963963964
Error: 0.8612538540596094
ROC: 0.8974280538861099
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.24563206577595068
precision: 0.23221757322175732
roc: 0.511318242343542
f1: 0.3769100169779287
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.3062692702980473
precision: 0.24749163879598662
roc: 0.5505992010652463
f1: 0.3967828418230563
recall: 1.0
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6917960088691796
Precision Average: 0.7027027027027027
Recall Average: 0.6812227074235808
Error: 0.8572895277207392
ROC: 0.7963160516983676
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7432432432432433
Precision Average: 0.6060606060606061
Recall Average: 0.9606986899563319
Error: 0.8439425051334702
ROC: 0.8843761906157499
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.0
Precision: 0.0
Recall: 0.0
Accuracy: 0.7648870636550308
ROC: 0.5
SVM:
F1 Score Average: 0.7432432432432433
Precision Average: 0.6060606060606061
Recall Average: 0.9606986899563319
Error: 0.8439425051334702
ROC: 0.8843761906157499
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.2351129363449692
precision: 0.2351129363449692
roc: 0.5
f1: 0.3807148794679967
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8100616016427105
precision: 0.627906976744186
roc: 0.6928548401277805
f1: 0.5386533665835411
recall: 0.47161572052401746
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7196261682242991
Precision Average: 0.7623762376237624
Recall Average: 0.6814159292035398
Error: 0.8767967145790554
ROC: 0.8086224031044437
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7462686567164178
Precision Average: 0.596816976127321
Recall Average: 0.995575221238938
Error: 0.8429158110882957
ROC: 0.8961833325446026
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.4422700587084149
Precision: 0.28391959798994976
Recall: 1.0
Accuracy: 0.41478439425051333
ROC: 0.6189839572192513
SVM:
F1 Score Average: 0.6512301013024603
Precision Average: 0.4838709677419355
Recall Average: 0.995575221238938
Error: 0.7525667351129364
ROC: 0.837359803132838
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.6960985626283368
precision: 0.4329501915708812
roc: 0.8021390374331551
f1: 0.6042780748663101
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7741273100616016
precision: 0.5166666666666667
roc: 0.6475971321754768
f1: 0.4581280788177341
recall: 0.41150442477876104
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7375271149674619
Precision Average: 0.6967213114754098
Recall Average: 0.783410138248848
Error: 0.8757700205338809
ROC: 0.8428279224929841
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7221297836938437
Precision Average: 0.5651041666666666
Recall Average: 1.0
Error: 0.8285420944558521
ROC: 0.8896961690885072
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6851851851851851
Precision: 0.5727554179566563
Recall: 0.8525345622119815
Accuracy: 0.8254620123203286
ROC: 0.8351180076581705
SVM:
F1 Score Average: 0.6581469648562299
Precision Average: 0.5036674816625917
Recall Average: 0.9493087557603687
Error: 0.7802874743326489
ROC: 0.8405724756344777
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.7546201232032854
precision: 0.46994535519125685
roc: 0.7681759796431462
f1: 0.5900514579759863
recall: 0.7926267281105991

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7885010266940452
precision: 0.5139240506329114
roc: 0.8409255550347297
f1: 0.6633986928104575
recall: 0.9354838709677419
AUC: 0.8107496382667069
F1: 0.7161267739171906
Accuracy: 0.8742836883324083
Recall: 0.6931737189391577
Precision: 0.7455243534688123

SVM without domain adaptationAUC: 0.8704260619751615
F1: 0.7194637052166708
Accuracy: 0.8327820348590592
Recall: 0.9399034308877028
Precision: 0.583591033449813

Perceptron without transfer learningrecall: 0.6772561329320539
accuracy: 0.7690767772991933
precision: 0.5592871393110516
roc: 0.7369781377189009
f1: 0.582273742307513

Perceptron with transfer learningrecall: 0.9576244447212188
accuracy: 0.5546380613315156
precision: 0.39222702944759114
roc: 0.6955033652151427
f1: 0.5387130335086511

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.5880451275784284
accuracy: 0.6948874224175954
precision: 0.555391414955047
roc: 0.6580248846737009
f1: 0.4540803430425309
SVM with BoW and transformed featuresAUC: 0.8785297592788994
F1: 0.7267457951324213
Accuracy: 0.827877328527322
Recall: 0.9721075243821187
Precision: 0.5843603961089968
MLP scoresAUC: 0.6412084641358591
F1: 0.43161885402786415
Accuracy: 0.6219927783206114
Recall: 0.6750114169469008
Precision: 0.3954286074268104
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.3764705882352941
Precision Average: 0.8421052631578947
Recall Average: 0.24242424242424243
Error: 0.8191126279863481
ROC: 0.6146041916967028
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.66
Precision Average: 0.49253731343283585
Recall Average: 1.0
Error: 0.7679180887372014
ROC: 0.8502202643171806
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.05882352941176471
Precision: 1.0
Recall: 0.030303030303030304
Accuracy: 0.7815699658703071
ROC: 0.5151515151515151
SVM:
F1 Score Average: 0.5814977973568282
Precision Average: 0.40993788819875776
Recall Average: 1.0
Error: 0.6757679180887372
ROC: 0.7907488986784141
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.9078498293515358
precision: 0.7671232876712328
roc: 0.8867974903217194
f1: 0.8057553956834531
recall: 0.8484848484848485

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7747440273037542
precision: 0.5
roc: 0.5161193432118542
f1: 0.08333333333333334
recall: 0.045454545454545456
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.4421052631578948
Precision Average: 0.75
Recall Average: 0.31343283582089554
Error: 0.8191126279863481
ROC: 0.641229692246731
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6839378238341969
Precision Average: 0.5238095238095238
Recall Average: 0.9850746268656716
Error: 0.7918088737201365
ROC: 0.8597939506009774
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.7570621468926554
Precision: 0.6090909090909091
Recall: 1.0
Accuracy: 0.8532423208191127
ROC: 0.9048672566371682
SVM:
F1 Score Average: 0.7243243243243244
Precision Average: 0.5677966101694916
Recall Average: 1.0
Error: 0.825938566552901
ROC: 0.8871681415929203
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8430034129692833
precision: 0.6019417475728155
roc: 0.8719786025624092
f1: 0.7294117647058823
recall: 0.9253731343283582

Perceptron with the transformed features and concatenated bag of words accuracy: 0.552901023890785
precision: 0.336734693877551
roc: 0.7049266939638092
f1: 0.5019011406844106
recall: 0.9850746268656716
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.5607476635514018
Precision Average: 0.6818181818181818
Recall Average: 0.47619047619047616
Error: 0.8401360544217688
ROC: 0.7077922077922079
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6847826086956522
Precision Average: 0.5206611570247934
Recall Average: 1.0
Error: 0.8027210884353742
ROC: 0.8744588744588745
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6146341463414634
Precision: 0.44366197183098594
Recall: 1.0
Accuracy: 0.7312925170068028
ROC: 0.829004329004329
SVM:
F1 Score Average: 0.6428571428571429
Precision Average: 0.47368421052631576
Recall Average: 1.0
Error: 0.7619047619047619
ROC: 0.8484848484848485
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.22448979591836735
precision: 0.21649484536082475
roc: 0.5064935064935066
f1: 0.3559322033898305
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8163265306122449
precision: 0.6153846153846154
roc: 0.6580086580086579
f1: 0.47058823529411764
recall: 0.38095238095238093
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6111111111111112
Precision Average: 0.7857142857142857
Recall Average: 0.5
Error: 0.8571428571428571
ROC: 0.7302631578947368
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6435643564356436
Precision Average: 0.47794117647058826
Recall Average: 0.9848484848484849
Error: 0.7551020408163265
ROC: 0.8367224880382775
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.39520958083832336
Precision: 0.24626865671641793
Recall: 1.0
Accuracy: 0.3129251700680272
ROC: 0.5570175438596492
SVM:
F1 Score Average: 0.6376811594202899
Precision Average: 0.46808510638297873
Recall Average: 1.0
Error: 0.7448979591836735
ROC: 0.8355263157894737
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.3979591836734694
precision: 0.2716049382716049
roc: 0.611842105263158
f1: 0.4271844660194175
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7789115646258503
precision: 0.5079365079365079
roc: 0.6744417862838916
f1: 0.49612403100775193
recall: 0.48484848484848486
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.6944444444444445
Precision Average: 0.5813953488372093
Recall Average: 0.8620689655172413
Error: 0.8503401360544217
ROC: 0.8547632963179427
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6408839779005524
Precision Average: 0.4715447154471545
Recall Average: 1.0
Error: 0.7789115646258503
ROC: 0.8622881355932204
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.763157894736842
Precision: 0.6170212765957447
Recall: 1.0
Accuracy: 0.8775510204081632
ROC: 0.923728813559322
SVM:
F1 Score Average: 0.6010362694300518
Precision Average: 0.42962962962962964
Recall Average: 1.0
Error: 0.7380952380952381
ROC: 0.836864406779661
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.3231292517006803
precision: 0.22568093385214008
roc: 0.5783898305084746
f1: 0.3682539682539682
recall: 1.0

Perceptron with the transformed features and concatenated bag of words accuracy: 0.3673469387755102
precision: 0.23770491803278687
roc: 0.6059322033898304
f1: 0.38410596026490074
recall: 1.0
AUC: 0.7097305091896643
F1: 0.5369758141000294
Accuracy: 0.8371688607183488
Recall: 0.47882330399057105
Precision: 0.7282066159055143

SVM without domain adaptationAUC: 0.8566967426017061
F1: 0.6626337533732091
Accuracy: 0.7792923312669777
Recall: 0.9939846223428311
Precision: 0.4972987772369792

Perceptron without transfer learningrecall: 0.8312289871734031
accuracy: 0.6301757563093497
precision: 0.4043121794172214
roc: 0.703867122683516
f1: 0.5071274203386198

Perceptron with transfer learningrecall: 0.9547715965626413
accuracy: 0.5392862947226673
precision: 0.4165691505457236
roc: 0.6911003070298535
f1: 0.5373075596105104

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.5792660076242167
accuracy: 0.6580460170416289
precision: 0.43955214704629225
roc: 0.6318857369716087
f1: 0.3872105401169029
SVM with BoW and transformed featuresAUC: 0.8397585222650635
F1: 0.6374793386777274
Accuracy: 0.7493208887650624
Recall: 1.0
Precision: 0.4698266889814347
MLP scoresAUC: 0.7459538916423967
F1: 0.5177774596442097
Accuracy: 0.7113161988344825
Recall: 0.806060606060606
Precision: 0.5832085628468116
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.726027397260274
Precision Average: 0.6708860759493671
Recall Average: 0.7910447761194029
Error: 0.8722044728434505
ROC: 0.8426768596044169
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.673469387755102
Precision Average: 0.5116279069767442
Recall Average: 0.9850746268656716
Error: 0.7955271565495208
ROC: 0.8644885329450309
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.5267857142857143
Precision: 0.37579617834394907
Recall: 0.8805970149253731
Accuracy: 0.6613418530351438
ROC: 0.7411115155927678
SVM:
F1 Score Average: 0.5535714285714287
Precision Average: 0.39490445859872614
Recall Average: 0.9253731343283582
Error: 0.6805111821086262
ROC: 0.7695971362698701
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.549520766773163
precision: 0.31862745098039214
roc: 0.7025543016624196
f1: 0.4797047970479704
recall: 0.9701492537313433

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8402555910543131
precision: 0.6808510638297872
roc: 0.7083181652712048
f1: 0.5614035087719299
recall: 0.47761194029850745
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7132867132867132
Precision Average: 0.6891891891891891
Recall Average: 0.7391304347826086
Error: 0.8690095846645367
ROC: 0.8224340698503207
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6666666666666666
Precision Average: 0.5075757575757576
Recall Average: 0.9710144927536232
Error: 0.7859424920127795
ROC: 0.8523105250653361
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.5098039215686275
Precision: 0.34946236559139787
Recall: 0.9420289855072463
Accuracy: 0.6006389776357828
ROC: 0.723063673081492
SVM:
F1 Score Average: 0.6473429951690821
Precision Average: 0.4855072463768116
Recall Average: 0.9710144927536232
Error: 0.7667731629392971
ROC: 0.840015443098123
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.6645367412140575
precision: 0.38461538461538464
roc: 0.7380612972202423
f1: 0.5333333333333333
recall: 0.8695652173913043

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7955271565495208
precision: 0.5294117647058824
roc: 0.7441197434069851
f1: 0.5844155844155844
recall: 0.6521739130434783
Fold 2: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.759124087591241
Precision Average: 0.8
Recall Average: 0.7222222222222222
Error: 0.8949044585987261
ROC: 0.8342516069788797
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.7578947368421053
Precision Average: 0.6101694915254238
Recall Average: 1.0
Error: 0.8535031847133758
ROC: 0.9049586776859504
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.6946107784431138
Precision: 0.6105263157894737
Recall: 0.8055555555555556
Accuracy: 0.8375796178343949
ROC: 0.8263314967860421
SVM:
F1 Score Average: 0.7244897959183674
Precision Average: 0.5725806451612904
Recall Average: 0.9861111111111112
Error: 0.8280254777070064
ROC: 0.8835514233241506
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.7802547770700637
precision: 1.0
roc: 0.5208333333333334
f1: 0.07999999999999999
recall: 0.041666666666666664

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8439490445859873
precision: 0.7090909090909091
roc: 0.7377754820936638
f1: 0.6141732283464567
recall: 0.5416666666666666
Fold 3: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7625899280575541
Precision Average: 0.7910447761194029
Recall Average: 0.7361111111111112
Error: 0.8949044585987261
ROC: 0.8391299357208447
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.5374449339207048
Precision Average: 0.3935483870967742
Recall Average: 0.8472222222222222
Error: 0.6656050955414012
ROC: 0.7293962350780532
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.05333333333333333
Precision: 0.6666666666666666
Recall: 0.027777777777777776
Accuracy: 0.7738853503184714
ROC: 0.5118227731864095
SVM:
F1 Score Average: 0.7282051282051283
Precision Average: 0.5772357723577236
Recall Average: 0.9861111111111112
Error: 0.8312101910828026
ROC: 0.88561753902663
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.7770700636942676
precision: 0.5119047619047619
roc: 0.7139003673094583
f1: 0.5512820512820512
recall: 0.5972222222222222

Perceptron with the transformed features and concatenated bag of words accuracy: 0.8535031847133758
precision: 0.8095238095238095
roc: 0.7195821854912764
f1: 0.5964912280701755
recall: 0.4722222222222222
Fold 4: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.7352941176470588
Precision Average: 0.78125
Recall Average: 0.6944444444444444
Error: 0.8853503184713376
ROC: 0.8182966023875115
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.6956521739130436
Precision Average: 0.5333333333333333
Recall Average: 1.0
Error: 0.7993630573248408
ROC: 0.8698347107438016
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.5551020408163265
Precision: 0.3930635838150289
Recall: 0.9444444444444444
Accuracy: 0.6528662420382165
ROC: 0.7552800734618916
SVM:
F1 Score Average: 0.6044444444444445
Precision Average: 0.4444444444444444
Recall Average: 0.9444444444444444
Error: 0.7165605095541401
ROC: 0.7966023875114783
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.8057324840764332
precision: 0.5797101449275363
roc: 0.7178604224058769
f1: 0.5673758865248227
recall: 0.5555555555555556

Perceptron with the transformed features and concatenated bag of words accuracy: 0.7866242038216561
precision: 0.6
roc: 0.5835055096418732
f1: 0.30927835051546393
recall: 0.20833333333333334
AUC: 0.8313578149083947
F1: 0.7392644487685682
Accuracy: 0.8832746586353555
Recall: 0.7365905977359579
Precision: 0.7464740082515918

SVM without domain adaptationAUC: 0.8441977363036346
F1: 0.6662255798195245
Accuracy: 0.7799881972283836
Recall: 0.9606622683683035
Precision: 0.5112509753016066

Perceptron without transfer learningrecall: 0.6637645107794362
accuracy: 0.7972059990639181
precision: 0.6010337667118788
roc: 0.7500986327506194
f1: 0.5679415597748636

Perceptron with transfer learningrecall: 0.6068317831134185
accuracy: 0.715422966565597
precision: 0.558971548485615
roc: 0.6786419443862661
f1: 0.4423392136376355

Perceptron with transfer learning and concatenated bag of wordsrecall: 0.4704016151128417
accuracy: 0.8239718361449706
precision: 0.6657755094300776
roc: 0.6986602171810007
f1: 0.5331523800239222
SVM with BoW and transformed featuresAUC: 0.8350767858460504
F1: 0.6516107584616901
Accuracy: 0.7646161046783745
Recall: 0.9626108587497295
Precision: 0.49493451338779926
MLP scoresAUC: 0.7115219064217206
F1: 0.4679271576894231
Accuracy: 0.7052624081724019
Recall: 0.7200807556420795
Precision: 0.4791030220413032
Fold 0: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.24561403508771926
Precision Average: 0.3684210526315789
Recall Average: 0.18421052631578946
Error: 0.9719137818419333
ROC: 0.5880865089716923
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.3052208835341365
Precision Average: 0.18009478672985782
Recall Average: 1.0
Error: 0.8870019595035924
ROC: 0.9420629604822506
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.0
Precision: 0.0
Recall: 0.0
Accuracy: 0.9725669497060745
ROC: 0.4986604152712659
SVM:
F1 Score Average: 0.3114754098360656
Precision Average: 0.18446601941747573
Recall Average: 1.0
Error: 0.8902677988242979
ROC: 0.9437374413931681
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}
Perceptron with the transformed featuresaccuracy: 0.3200522534291313
precision: 0.031746031746031744
roc: 0.6000810801283181
f1: 0.06131650135256988
recall: 0.8947368421052632

Perceptron with the transformed features and concatenated bag of words accuracy: 0.32984977139124755
precision: 0.03571428571428571
roc: 0.6563965170797053
f1: 0.0689655172413793
recall: 1.0
Fold 1: 
SVM with domain adaptation metrics:SVM:
F1 Score Average: 0.17777777777777776
Precision Average: 1.0
Recall Average: 0.0975609756097561
Error: 0.9758327890267798
ROC: 0.5487804878048781
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

SVM without domain adaptationSVM:
F1 Score Average: 0.1818181818181818
Precision Average: 0.11052631578947368
Recall Average: 0.5121951219512195
Error: 0.8765512736773351
ROC: 0.6993861515796366
HyperParameters: {'score_model': 'f1', 'gamma_range': array([ 0.001,  0.01 ,  0.1  ,  1.   ]), 'c_range': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,
         1.00000000e+01,   1.00000000e+02]), 'kernel': 'rbf'}

Perceptron with only bag of wordsMLP:
F1 Score: 0.08403361344537816
Precision: 0.04597701149425287
Recall: 0.4878048780487805
Accuracy: 0.7152188112344873
ROC: 0.6046406940579473
